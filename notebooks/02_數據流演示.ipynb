{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# NeRF 數據流演示 📊\n",
       "\n",
       "本筆記本詳細演示了 NeRF 從原始輸入數據到最終渲染的完整數據流程。\n",
       "\n",
       "## 📋 內容概覽\n",
       "1. 創建合成數據集\n",
       "2. 數據加載和預處理\n",
       "3. 射線生成過程\n",
       "4. 3D 點採樣\n",
       "5. 位置編碼\n",
       "6. 批次數據準備\n",
       "7. 數據流可視化"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 導入必要的庫\n",
       "import sys\n",
       "import os\n",
       "sys.path.append('..')\n",
       "\n",
       "import torch\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import json\n",
       "from pathlib import Path\n",
       "\n",
       "# 導入我們的模組\n",
       "from src.utils.data_utils import NeRFDataLoader, create_synthetic_dataset\n",
       "from src.models.encoding import PositionalEncoder\n",
       "\n",
       "# 設置隨機種子\n",
       "torch.manual_seed(42)\n",
       "np.random.seed(42)\n",
       "\n",
       "print(\"🚀 NeRF 數據流演示開始！\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. 創建合成數據集 🎨\n",
       "\n",
       "首先，我們創建一個包含 100 張圖像的合成數據集來演示數據流程。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 創建合成數據集\n",
       "n_images = 100\n",
       "image_size = (64, 64)  # (H, W)\n",
       "output_dir = \"../data/synthetic_demo\"\n",
       "\n",
       "print(f\"📊 創建數據集參數:\")\n",
       "print(f\"   - 圖像數量: {n_images}\")\n",
       "print(f\"   - 圖像尺寸: {image_size}\")\n",
       "print(f\"   - 輸出目錄: {output_dir}\")\n",
       "\n",
       "# 創建數據集\n",
       "dataset = create_synthetic_dataset(\n",
       "    n_images=n_images,\n",
       "    image_size=image_size,\n",
       "    output_dir=output_dir\n",
       ")\n",
       "\n",
       "print(f\"\\n✅ 數據集創建完成！\")\n",
       "print(f\"   - 訓練集: 80 張圖像\")\n",
       "print(f\"   - 驗證集: 10 張圖像\")\n",
       "print(f\"   - 測試集: 10 張圖像\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 可視化原始數據"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 可視化一些樣本圖像\n",
       "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
       "fig.suptitle('合成數據集樣本圖像', fontsize=16)\n",
       "\n",
       "for i in range(10):\n",
       "    row = i // 5\n",
       "    col = i % 5\n",
       "    \n",
       "    img = dataset['images'][i * 10]  # 每隔10張取一張\n",
       "    axes[row, col].imshow(img)\n",
       "    axes[row, col].set_title(f'視角 {i * 10 + 1}')\n",
       "    axes[row, col].axis('off')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "print(f\"📸 圖像數據形狀: {dataset['images'].shape}\")\n",
       "print(f\"📷 相機位姿形狀: {dataset['poses'].shape}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. 數據加載和預處理 📂\n",
       "\n",
       "使用我們的數據加載器來處理數據。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 初始化數據加載器\n",
       "data_loader = NeRFDataLoader(\n",
       "    data_dir=output_dir,\n",
       "    scene_name=\"synthetic_demo\",\n",
       "    image_scale=1.0,\n",
       "    white_background=True\n",
       ")\n",
       "\n",
       "# 加載訓練數據\n",
       "train_images = data_loader.load_images(\"train\")\n",
       "train_poses, train_intrinsics = data_loader.load_camera_parameters(\"train\")\n",
       "\n",
       "print(f\"\\n📊 訓練數據統計:\")\n",
       "print(f\"   - 圖像形狀: {train_images.shape}\")\n",
       "print(f\"   - 位姿形狀: {train_poses.shape}\")\n",
       "print(f\"   - 內參形狀: {train_intrinsics.shape if train_intrinsics is not None else 'None'}\")\n",
       "print(f\"   - 圖像尺寸: {data_loader.image_size}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 分析相機軌跡"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 提取相機位置\n",
       "camera_positions = train_poses[:, :3, 3].numpy()  # [N, 3]\n",
       "\n",
       "# 3D 可視化相機軌跡\n",
       "fig = plt.figure(figsize=(12, 5))\n",
       "\n",
       "# 3D 軌跡圖\n",
       "ax1 = fig.add_subplot(121, projection='3d')\n",
       "ax1.plot(camera_positions[:, 0], camera_positions[:, 1], camera_positions[:, 2], 'b-o', markersize=3)\n",
       "ax1.scatter([0], [0], [0], c='red', s=100, marker='*', label='場景中心')\n",
       "ax1.set_xlabel('X')\n",
       "ax1.set_ylabel('Y')\n",
       "ax1.set_zlabel('Z')\n",
       "ax1.set_title('相機軌跡 (3D)')\n",
       "ax1.legend()\n",
       "\n",
       "# 俯視圖\n",
       "ax2 = fig.add_subplot(122)\n",
       "ax2.plot(camera_positions[:, 0], camera_positions[:, 2], 'b-o', markersize=3)\n",
       "ax2.scatter([0], [0], c='red', s=100, marker='*', label='場景中心')\n",
       "ax2.set_xlabel('X')\n",
       "ax2.set_ylabel('Z')\n",
       "ax2.set_title('相機軌跡 (俯視圖)')\n",
       "ax2.legend()\n",
       "ax2.axis('equal')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "print(f\"📍 相機位置統計:\")\n",
       "print(f\"   - X 範圍: [{camera_positions[:, 0].min():.2f}, {camera_positions[:, 0].max():.2f}]\")\n",
       "print(f\"   - Y 範圍: [{camera_positions[:, 1].min():.2f}, {camera_positions[:, 1].max():.2f}]\")\n",
       "print(f\"   - Z 範圍: [{camera_positions[:, 2].min():.2f}, {camera_positions[:, 2].max():.2f}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. 射線生成過程 🔫\n",
       "\n",
       "演示如何從像素座標生成 3D 射線。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 為所有訓練圖像創建射線\n",
       "print(\"🔫 生成射線...\")\n",
       "rays_o, rays_d = data_loader.create_rays(train_poses, train_intrinsics)\n",
       "\n",
       "print(f\"\\n📊 射線數據統計:\")\n",
       "print(f\"   - 射線起點形狀: {rays_o.shape}\")\n",
       "print(f\"   - 射線方向形狀: {rays_d.shape}\")\n",
       "print(f\"   - 每張圖像的射線數: {rays_o.shape[1] * rays_o.shape[2]}\")\n",
       "print(f\"   - 總射線數: {rays_o.shape[0] * rays_o.shape[1] * rays_o.shape[2]}\")\n",
       "\n",
       "# 分析第一張圖像的射線\n",
       "first_rays_o = rays_o[0]  # [H, W, 3]\n",
       "first_rays_d = rays_d[0]  # [H, W, 3]\n",
       "\n",
       "print(f\"\\n🔍 第一張圖像射線分析:\")\n",
       "print(f\"   - 射線起點 (都相同): {first_rays_o[0, 0]}\")\n",
       "print(f\"   - 中心射線方向: {first_rays_d[32, 32]}\")\n",
       "print(f\"   - 左上角射線方向: {first_rays_d[0, 0]}\")\n",
       "print(f\"   - 右下角射線方向: {first_rays_d[-1, -1]}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 可視化射線方向"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 可視化射線方向的分佈\n",
       "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
       "\n",
       "# X 方向分量\n",
       "im1 = axes[0].imshow(first_rays_d[:, :, 0].numpy(), cmap='RdBu')\n",
       "axes[0].set_title('射線方向 X 分量')\n",
       "axes[0].axis('off')\n",
       "plt.colorbar(im1, ax=axes[0])\n",
       "\n",
       "# Y 方向分量\n",
       "im2 = axes[1].imshow(first_rays_d[:, :, 1].numpy(), cmap='RdBu')\n",
       "axes[1].set_title('射線方向 Y 分量')\n",
       "axes[1].axis('off')\n",
       "plt.colorbar(im2, ax=axes[1])\n",
       "\n",
       "# Z 方向分量\n",
       "im3 = axes[2].imshow(first_rays_d[:, :, 2].numpy(), cmap='RdBu')\n",
       "axes[2].set_title('射線方向 Z 分量')\n",
       "axes[2].axis('off')\n",
       "plt.colorbar(im3, ax=axes[2])\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. 訓練數據採樣 🎯\n",
       "\n",
       "演示如何從大量射線中採樣訓練批次。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 獲取一個訓練批次\n",
       "batch_size = 1024\n",
       "batch_data = data_loader.get_training_data(batch_size=batch_size)\n",
       "\n",
       "print(f\"🎯 訓練批次數據:\")\n",
       "print(f\"   - 批次大小: {batch_size}\")\n",
       "print(f\"   - 射線起點: {batch_data['rays_o'].shape}\")\n",
       "print(f\"   - 射線方向: {batch_data['rays_d'].shape}\")\n",
       "print(f\"   - 目標顏色: {batch_data['target_rgb'].shape}\")\n",
       "print(f\"   - 來源圖像索引: {batch_data['img_idx']}\")\n",
       "\n",
       "# 分析目標顏色分佈\n",
       "target_rgb = batch_data['target_rgb']\n",
       "print(f\"\\n🎨 目標顏色統計:\")\n",
       "print(f\"   - R 通道範圍: [{target_rgb[:, 0].min():.3f}, {target_rgb[:, 0].max():.3f}]\")\n",
       "print(f\"   - G 通道範圍: [{target_rgb[:, 1].min():.3f}, {target_rgb[:, 1].max():.3f}]\")\n",
       "print(f\"   - B 通道範圍: [{target_rgb[:, 2].min():.3f}, {target_rgb[:, 2].max():.3f}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 可視化採樣的射線"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 可視化採樣的射線在圖像中的分佈\n",
       "img_idx = batch_data['img_idx']\n",
       "ray_indices = batch_data['ray_indices']\n",
       "h, w = data_loader.image_size\n",
       "\n",
       "# 創建採樣掩碼\n",
       "sample_mask = torch.zeros(h * w, dtype=torch.bool)\n",
       "sample_mask[ray_indices] = True\n",
       "sample_mask = sample_mask.reshape(h, w)\n",
       "\n",
       "# 可視化\n",
       "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
       "\n",
       "# 原始圖像\n",
       "axes[0].imshow(train_images[img_idx])\n",
       "axes[0].set_title(f'原始圖像 (索引 {img_idx})')\n",
       "axes[0].axis('off')\n",
       "\n",
       "# 採樣掩碼\n",
       "axes[1].imshow(sample_mask.numpy(), cmap='gray')\n",
       "axes[1].set_title(f'採樣射線分佈 ({batch_size} 條射線)')\n",
       "axes[1].axis('off')\n",
       "\n",
       "# 採樣的顏色\n",
       "sampled_colors = torch.zeros(h, w, 3)\n",
       "sampled_colors.view(-1, 3)[ray_indices] = target_rgb\n",
       "axes[2].imshow(sampled_colors)\n",
       "axes[2].set_title('採樣的像素顏色')\n",
       "axes[2].axis('off')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "print(f\"📊 採樣統計:\")\n",
       "print(f\"   - 採樣比例: {batch_size / (h * w) * 100:.1f}%\")\n",
       "print(f\"   - 總像素數: {h * w}\")\n",
       "print(f\"   - 採樣像素數: {batch_size}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. 3D 點採樣 📍\n",
       "\n",
       "演示如何沿射線採樣 3D 點。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 沿射線採樣 3D 點\n",
       "near, far = 2.0, 6.0\n",
       "n_samples = 64\n",
       "\n",
       "# 獲取批次射線\n",
       "batch_rays_o = batch_data['rays_o']  # [1024, 3]\n",
       "batch_rays_d = batch_data['rays_d']  # [1024, 3]\n",
       "\n",
       "print(f\"📍 3D 點採樣參數:\")\n",
       "print(f\"   - 近平面: {near}\")\n",
       "print(f\"   - 遠平面: {far}\")\n",
       "print(f\"   - 每條射線採樣點數: {n_samples}\")\n",
       "\n",
       "# 分層採樣\n",
       "t_vals = torch.linspace(0., 1., steps=n_samples)\n",
       "z_vals = near * (1. - t_vals) + far * t_vals  # 深度值\n",
       "z_vals = z_vals.expand([batch_size, n_samples])  # [1024, 64]\n",
       "\n",
       "# 添加隨機擾動 (分層採樣)\n",
       "mids = 0.5 * (z_vals[..., 1:] + z_vals[..., :-1])\n",
       "upper = torch.cat([mids, z_vals[..., -1:]], -1)\n",
       "lower = torch.cat([z_vals[..., :1], mids], -1)\n",
       "t_rand = torch.rand(z_vals.shape)\n",
       "z_vals_perturbed = lower + (upper - lower) * t_rand\n",
       "\n",
       "# 計算 3D 點座標\n",
       "pts = batch_rays_o[..., None, :] + batch_rays_d[..., None, :] * z_vals_perturbed[..., :, None]\n",
       "\n",
       "print(f\"\\n📊 採樣結果:\")\n",
       "print(f\"   - 深度值形狀: {z_vals_perturbed.shape}\")\n",
       "print(f\"   - 3D 點形狀: {pts.shape}\")\n",
       "print(f\"   - 總採樣點數: {pts.shape[0] * pts.shape[1]}\")\n",
       "\n",
       "print(f\"\\n🔍 深度值統計:\")\n",
       "print(f\"   - 最小深度: {z_vals_perturbed.min():.3f}\")\n",
       "print(f\"   - 最大深度: {z_vals_perturbed.max():.3f}\")\n",
       "print(f\"   - 平均深度: {z_vals_perturbed.mean():.3f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 可視化 3D 點分佈"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 可視化一條射線上的採樣點\n",
       "ray_idx = 0\n",
       "sample_ray_o = batch_rays_o[ray_idx]  # [3]\n",
       "sample_ray_d = batch_rays_d[ray_idx]  # [3]\n",
       "sample_pts = pts[ray_idx]  # [64, 3]\n",
       "sample_z_vals = z_vals_perturbed[ray_idx]  # [64]\n",
       "\n",
       "fig = plt.figure(figsize=(15, 5))\n",
       "\n",
       "# 3D 散點圖\n",
       "ax1 = fig.add_subplot(131, projection='3d')\n",
       "ax1.scatter(sample_pts[:, 0], sample_pts[:, 1], sample_pts[:, 2], \n",
       "           c=sample_z_vals, cmap='viridis', s=20)\n",
       "ax1.plot([sample_ray_o[0], sample_ray_o[0] + 8*sample_ray_d[0]], \n",
       "         [sample_ray_o[1], sample_ray_o[1] + 8*sample_ray_d[1]], \n",
       "         [sample_ray_o[2], sample_ray_o[2] + 8*sample_ray_d[2]], 'r-', linewidth=2)\n",
       "ax1.scatter(*sample_ray_o, c='red', s=100, marker='o', label='射線起點')\n",
       "ax1.set_xlabel('X')\n",
       "ax1.set_ylabel('Y')\n",
       "ax1.set_zlabel('Z')\n",
       "ax1.set_title('3D 點採樣 (單條射線)')\n",
       "ax1.legend()\n",
       "\n",
       "# 深度值分佈\n",
       "ax2 = fig.add_subplot(132)\n",
       "ax2.hist(z_vals_perturbed.flatten().numpy(), bins=50, alpha=0.7, color='blue')\n",
       "ax2.axvline(near, color='red', linestyle='--', label=f'近平面 ({near})')\n",
       "ax2.axvline(far, color='red', linestyle='--', label=f'遠平面 ({far})')\n",
       "ax2.set_xlabel('深度值')\n",
       "ax2.set_ylabel('頻率')\n",
       "ax2.set_title('深度值分佈')\n",
       "ax2.legend()\n",
       "\n",
       "# 單條射線的深度值\n",
       "ax3 = fig.add_subplot(133)\n",
       "ax3.plot(range(n_samples), sample_z_vals.numpy(), 'bo-', markersize=4)\n",
       "ax3.axhline(near, color='red', linestyle='--', alpha=0.7, label=f'近平面 ({near})')\n",
       "ax3.axhline(far, color='red', linestyle='--', alpha=0.7, label=f'遠平面 ({far})')\n",
       "ax3.set_xlabel('採樣點索引')\n",
       "ax3.set_ylabel('深度值')\n",
       "ax3.set_title(f'單條射線深度值 (射線 {ray_idx})')\n",
       "ax3.legend()\n",
       "ax3.grid(True, alpha=0.3)\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. 位置編碼 🔢\n",
       "\n",
       "演示位置編碼如何將 3D 座標轉換為高維特徵。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 創建位置編碼器\n",
       "pos_encoder = PositionalEncoder(\n",
       "    input_dims=3,\n",
       "    max_freq_log2=6,\n",
       "    num_freqs=6,\n",
       "    include_input=True\n",
       ")\n",
       "\n",
       "dir_encoder = PositionalEncoder(\n",
       "    input_dims=3,\n",
       "    max_freq_log2=4,\n",
       "    num_freqs=4,\n",
       "    include_input=True\n",
       ")\n",
       "\n",
       "print(f\"🔢 位置編碼器參數:\")\n",
       "print(f\"   - 位置編碼維度: {pos_encoder.out_dim}\")\n",
       "print(f\"   - 方向編碼維度: {dir_encoder.out_dim}\")\n",
       "print(f\"   - 位置頻率數: {pos_encoder.num_freqs}\")\n",
       "print(f\"   - 方向頻率數: {dir_encoder.num_freqs}\")\n",
       "\n",
       "# 準備數據進行編碼\n",
       "pts_flat = pts.reshape(-1, 3)  # [65536, 3]\n",
       "\n",
       "# 準備觀看方向\n",
       "viewdirs = batch_rays_d / torch.norm(batch_rays_d, dim=-1, keepdim=True)\n",
       "viewdirs = viewdirs[:, None].expand(pts.shape)  # [1024, 64, 3]\n",
       "dirs_flat = viewdirs.reshape(-1, 3)  # [65536, 3]\n",
       "\n",
       "print(f\"\\n📊 編碼前數據:\")\n",
       "print(f\"   - 3D 點形狀: {pts_flat.shape}\")\n",
       "print(f\"   - 觀看方向形狀: {dirs_flat.shape}\")\n",
       "\n",
       "# 進行位置編碼\n",
       "pts_encoded = pos_encoder.encode(pts_flat)\n",
       "dirs_encoded = dir_encoder.encode(dirs_flat)\n",
       "\n",
       "print(f\"\\n📊 編碼後數據:\")\n",
       "print(f\"   - 編碼位置形狀: {pts_encoded.shape}\")\n",
       "print(f\"   - 編碼方向形狀: {dirs_encoded.shape}\")\n",
       "print(f\"   - 總特徵維度: {pts_encoded.shape[1] + dirs_encoded.shape[1]}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 可視化位置編碼效果"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 可視化位置編碼的效果\n",
       "sample_pts = pts_flat[:1000]  # 取前1000個點\n",
       "sample_encoded = pos_encoder.encode(sample_pts)\n",
       "\n",
       "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
       "\n",
       "# 原始座標\n",
       "for i, coord_name in enumerate(['X', 'Y', 'Z']):\n",
       "    axes[0, i].scatter(range(1000), sample_pts[:, i].numpy(), alpha=0.6, s=1)\n",
       "    axes[0, i].set_title(f'原始 {coord_name} 座標')\n",
       "    axes[0, i].set_xlabel('點索引')\n",
       "    axes[0, i].set_ylabel(f'{coord_name} 值')\n",
       "\n",
       "# 編碼後的特徵 (顯示前幾個維度)\n",
       "feature_indices = [3, 10, 20]  # 選擇一些編碼維度\n",
       "for i, feat_idx in enumerate(feature_indices):\n",
       "    axes[1, i].scatter(range(1000), sample_encoded[:, feat_idx].numpy(), alpha=0.6, s=1)\n",
       "    axes[1, i].set_title(f'編碼特徵維度 {feat_idx}')\n",
       "    axes[1, i].set_xlabel('點索引')\n",
       "    axes[1, i].set_ylabel('特徵值')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "# 分析編碼特徵的統計信息\n",
       "print(f\"🔍 編碼特徵統計:\")\n",
       "print(f\"   - 特徵值範圍: [{sample_encoded.min():.3f}, {sample_encoded.max():.3f}]\")\n",
       "print(f\"   - 特徵均值: {sample_encoded.mean():.3f}\")\n",
       "print(f\"   - 特徵標準差: {sample_encoded.std():.3f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. 完整數據流程總結 📋\n",
       "\n",
       "總結整個數據流程中的關鍵數據變換。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 創建數據流程總結\n",
       "data_flow_summary = {\n",
       "    \"階段1_原始數據\": {\n",
       "        \"圖像數量\": n_images,\n",
       "        \"圖像尺寸\": f\"{image_size[0]}×{image_size[1]}\",\n",
       "        \"訓練圖像\": train_images.shape,\n",
       "        \"相機位姿\": train_poses.shape\n",
       "    },\n",
       "    \"階段2_射線生成\": {\n",
       "        \"射線起點\": rays_o.shape,\n",
       "        \"射線方向\": rays_d.shape,\n",
       "        \"每圖像射線數\": rays_o.shape[1] * rays_o.shape[2],\n",
       "        \"總射線數\": rays_o.shape[0] * rays_o.shape[1] * rays_o.shape[2]\n",
       "    },\n",
       "    \"階段3_批次採樣\": {\n",
       "        \"批次大小\": batch_size,\n",
       "        \"批次射線起點\": batch_data['rays_o'].shape,\n",
       "        \"批次射線方向\": batch_data['rays_d'].shape,\n",
       "        \"目標顏色\": batch_data['target_rgb'].shape\n",
       "    },\n",
       "    \"階段4_3D點採樣\": {\n",
       "        \"每射線採樣點數\": n_samples,\n",
       "        \"3D點座標\": pts.shape,\n",
       "        \"深度值\": z_vals_perturbed.shape,\n",
       "        \"總採樣點數\": pts.shape[0] * pts.shape[1]\n",
       "    },\n",
       "    \"階段5_位置編碼\": {\n",
       "        \"原始3D點\": pts_flat.shape,\n",
       "        \"編碼位置\": pts_encoded.shape,\n",
       "        \"編碼方向\": dirs_encoded.shape,\n",
       "        \"總特徵維度\": pts_encoded.shape[1] + dirs_encoded.shape[1]\n",
       "    }\n",
       "}\n",
       "\n",
       "print(\"📋 NeRF 數據流程總結\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "for stage, info in data_flow_summary.items():\n",
       "    print(f\"\\n{stage.replace('_', ' ')}:\")\n",
       "    for key, value in info.items():\n",
       "        print(f\"   {key}: {value}\")\n",
       "\n",
       "# 計算記憶體使用估算\n",
       "print(\"\\n💾 記憶體使用估算:\")\n",
       "print(\"=\" * 30)\n",
       "\n",
       "# 假設 float32 (4 bytes)\n",
       "bytes_per_float = 4\n",
       "\n",
       "image_memory = np.prod(train_images.shape) * bytes_per_float / 1024**2\n",
       "rays_memory = np.prod(rays_o.shape) * 2 * bytes_per_float / 1024**2  # 起點+方向\n",
       "batch_memory = (np.prod(pts_encoded.shape) + np.prod(dirs_encoded.shape)) * bytes_per_float / 1024**2\n",
       "\n",
       "print(f\"   訓練圖像: {image_memory:.1f} MB\")\n",
       "print(f\"   所有射線: {rays_memory:.1f} MB\")\n",
       "print(f\"   批次編碼特徵: {batch_memory:.1f} MB\")\n",
       "print(f\"   總計: {image_memory + rays_memory + batch_memory:.1f} MB\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. 數據流可視化 📊\n",
       "\n",
       "創建一個完整的數據流程圖。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 創建數據流程可視化\n",
       "import matplotlib.patches as patches\n",
       "\n",
       "fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
       "\n",
       "# 定義流程步驟\n",
       "steps = [\n",
       "    {\"name\": \"原始圖像\\n100張 64×64×3\", \"pos\": (1, 9), \"color\": \"lightblue\"},\n",
       "    {\"name\": \"相機參數\\n100個 4×4 位姿\", \"pos\": (3, 9), \"color\": \"lightgreen\"},\n",
       "    {\"name\": \"數據分割\\n80/10/10\", \"pos\": (2, 7.5), \"color\": \"lightyellow\"},\n",
       "    {\"name\": \"射線生成\\n80×64×64×3\", \"pos\": (2, 6), \"color\": \"lightcoral\"},\n",
       "    {\"name\": \"隨機採樣\\n1024 條射線\", \"pos\": (2, 4.5), \"color\": \"lightpink\"},\n",
       "    {\"name\": \"3D點採樣\\n1024×64×3\", \"pos\": (2, 3), \"color\": \"lightsteelblue\"},\n",
       "    {\"name\": \"位置編碼\\n65536×39\", \"pos\": (1, 1.5), \"color\": \"lightsalmon\"},\n",
       "    {\"name\": \"方向編碼\\n65536×27\", \"pos\": (3, 1.5), \"color\": \"lightsalmon\"},\n",
       "    {\"name\": \"NeRF網絡\\nRGB + 密度\", \"pos\": (2, 0), \"color\": \"lightgray\"}\n",
       "]\n",
       "\n",
       "# 繪製步驟框\n",
       "for step in steps:\n",
       "    rect = patches.FancyBboxPatch(\n",
       "        (step[\"pos\"][0]-0.4, step[\"pos\"][1]-0.3), 0.8, 0.6,\n",
       "        boxstyle=\"round,pad=0.1\", \n",
       "        facecolor=step[\"color\"], \n",
       "        edgecolor=\"black\",\n",
       "        linewidth=1\n",
       "    )\n",
       "    ax.add_patch(rect)\n",
       "    ax.text(step[\"pos\"][0], step[\"pos\"][1], step[\"name\"], \n",
       "           ha=\"center\", va=\"center\", fontsize=10, weight=\"bold\")\n",
       "\n",
       "# 繪製箭頭\n",
       "arrows = [\n",
       "    ((2, 8.7), (2, 8.1)),      # 數據分割\n",
       "    ((2, 7.2), (2, 6.6)),      # 射線生成\n",
       "    ((2, 5.7), (2, 5.1)),      # 隨機採樣\n",
       "    ((2, 4.2), (2, 3.6)),      # 3D點採樣\n",
       "    ((1.6, 2.7), (1.2, 2.1)),  # 位置編碼\n",
       "    ((2.4, 2.7), (2.8, 2.1)),  # 方向編碼\n",
       "    ((1.5, 1.2), (1.8, 0.6)),  # 到NeRF網絡\n",
       "    ((2.5, 1.2), (2.2, 0.6))   # 到NeRF網絡\n",
       "]\n",
       "\n",
       "for start, end in arrows:\n",
       "    ax.annotate(\"\", xy=end, xytext=start,\n",
       "               arrowprops=dict(arrowstyle=\"->\", lw=2, color=\"darkblue\"))\n",
       "\n",
       "# 添加數據量標註\n",
       "data_annotations = [\n",
       "    ((4.5, 9), \"100 張圖像\\n每張 4096 像素\"),\n",
       "    ((4.5, 6), \"327,680,000 條射線\\n(80×64×64×1000)\"),\n",
       "    ((4.5, 4.5), \"每批次 1024 條\\n隨機採樣\"),\n",
       "    ((4.5, 3), \"65,536 個 3D 點\\n(1024×64)\"),\n",
       "    ((4.5, 1.5), \"高維特徵向量\\n39+27=66 維\"),\n",
       "    ((4.5, 0), \"RGB 顏色 + 密度\\n每點 4 個值\")\n",
       "]\n",
       "\n",
       "for pos, text in data_annotations:\n",
       "    ax.text(pos[0], pos[1], text, ha=\"left\", va=\"center\", \n",
       "           fontsize=9, style=\"italic\", color=\"darkgreen\")\n",
       "\n",
       "ax.set_xlim(0, 6)\n",
       "ax.set_ylim(-0.5, 10)\n",
       "ax.set_title(\"NeRF 數據流程圖\", fontsize=16, weight=\"bold\", pad=20)\n",
       "ax.axis('off')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 🎯 總結\n",
       "\n",
       "通過這個演示，我們詳細了解了 NeRF 的完整數據流程：\n",
       "\n",
       "### 關鍵數據變換\n",
       "1. **圖像 → 射線**: 每個像素生成一條 3D 射線\n",
       "2. **射線 → 3D點**: 沿射線採樣多個 3D 點\n",
       "3. **3D點 → 高維特徵**: 位置編碼擴展特徵維度\n",
       "4. **特徵 → 預測**: NeRF 網絡預測顏色和密度\n",
       "5. **預測 → 像素**: 體積渲染合成最終像素顏色\n",
       "\n",
       "### 數據規模\n",
       "- **輸入**: 100 張 64×64 圖像\n",
       "- **射線**: 每張圖像 4,096 條射線\n",
       "- **採樣**: 每條射線 64 個 3D 點\n",
       "- **特徵**: 每個點 66 維編碼特徵\n",
       "- **批次**: 每次處理 1,024 條射線\n",
       "\n",
       "### 設計優勢\n",
       "- **並行化**: 所有計算都可以批次處理\n",
       "- **隨機性**: 隨機採樣提高訓練效率\n",
       "- **可擴展**: 支持不同解析度和場景規模\n",
       "- **模組化**: 每個步驟都可以獨立優化\n",
       "\n",
       "這個數據流程設計使得 NeRF 能夠高效地從 2D 圖像學習 3D 場景表示！"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }