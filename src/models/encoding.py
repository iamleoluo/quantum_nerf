"""
ä½ç½®ç·¨ç¢¼æ¨¡çµ„

å¯¦ç¾ NeRF ä¸­çš„ä½ç½®ç·¨ç¢¼åŠŸèƒ½ï¼š
- æ­£å¼¦é¤˜å¼¦ä½ç½®ç·¨ç¢¼
- å¤šé »ç‡ç‰¹å¾µæå–
- é‡å­ç·¨ç¢¼æ¥å£é ç•™
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Optional, List
from .base import BaseModel, QuantumReadyMixin


class PositionalEncoder(QuantumReadyMixin):
    """
    ä½ç½®ç·¨ç¢¼å™¨
    
    ä½¿ç”¨æ­£å¼¦å’Œé¤˜å¼¦å‡½æ•¸å° 3D åº§æ¨™é€²è¡Œç·¨ç¢¼ï¼Œ
    å°‡ä½ç¶­åº§æ¨™æ˜ å°„åˆ°é«˜ç¶­ç‰¹å¾µç©ºé–“ã€‚
    """
    
    def __init__(self, input_dims: int = 3, max_freq_log2: int = 10, 
                 num_freqs: int = 10, include_input: bool = True,
                 log_sampling: bool = True):
        """
        åˆå§‹åŒ–ä½ç½®ç·¨ç¢¼å™¨
        
        Args:
            input_dims: è¼¸å…¥ç¶­åº¦ (é€šå¸¸æ˜¯ 3 for 3D åº§æ¨™)
            max_freq_log2: æœ€å¤§é »ç‡çš„ log2 å€¼
            num_freqs: é »ç‡æ•¸é‡
            include_input: æ˜¯å¦åŒ…å«åŸå§‹è¼¸å…¥
            log_sampling: æ˜¯å¦ä½¿ç”¨å°æ•¸æ¡æ¨£é »ç‡
        """
        super().__init__()
        
        self.input_dims = input_dims
        self.max_freq_log2 = max_freq_log2
        self.num_freqs = num_freqs
        self.include_input = include_input
        self.log_sampling = log_sampling
        
        # é€±æœŸå‡½æ•¸
        self.periodic_fns = [torch.sin, torch.cos]
        
        # å‰µå»ºé »ç‡å¸¶
        if log_sampling:
            freq_bands = 2.**torch.linspace(0., max_freq_log2, steps=num_freqs)
        else:
            freq_bands = torch.linspace(2.**0., 2.**max_freq_log2, steps=num_freqs)
        
        # è¨»å†Šç‚ºç·©è¡å€ (ä¸æœƒè¢«ç•¶ä½œåƒæ•¸è¨“ç·´)
        self.register_buffer('freq_bands', freq_bands)
        
        # è¨ˆç®—è¼¸å‡ºç¶­åº¦
        out_dim = 0
        if include_input:
            out_dim += input_dims
        out_dim += input_dims * len(self.periodic_fns) * num_freqs
        self.out_dim = out_dim
        
        print(f"ğŸ”¢ ä½ç½®ç·¨ç¢¼å™¨åˆå§‹åŒ–:")
        print(f"   - è¼¸å…¥ç¶­åº¦: {input_dims}")
        print(f"   - é »ç‡æ•¸é‡: {num_freqs}")
        print(f"   - è¼¸å‡ºç¶­åº¦: {out_dim}")
        print(f"   - é »ç‡ç¯„åœ: [1, {2**max_freq_log2}]")
    
    def encode(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        å°è¼¸å…¥åº§æ¨™é€²è¡Œä½ç½®ç·¨ç¢¼
        
        Args:
            inputs: [..., input_dims] è¼¸å…¥åº§æ¨™
            
        Returns:
            encoded: [..., out_dim] ç·¨ç¢¼å¾Œçš„ç‰¹å¾µ
        """
        outputs = []
        
        # åŒ…å«åŸå§‹è¼¸å…¥
        if self.include_input:
            outputs.append(inputs)
        
        # å°æ¯å€‹é »ç‡æ‡‰ç”¨æ­£å¼¦å’Œé¤˜å¼¦å‡½æ•¸
        for freq in self.freq_bands:
            for p_fn in self.periodic_fns:
                outputs.append(p_fn(inputs * freq))
        
        return torch.cat(outputs, dim=-1)
    
    def encode_with_gradients(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        ç·¨ç¢¼ä¸¦ä¿ç•™æ¢¯åº¦ä¿¡æ¯ (ç”¨æ–¼è¨“ç·´)
        
        Args:
            inputs: [..., input_dims] è¼¸å…¥åº§æ¨™
            
        Returns:
            encoded: [..., out_dim] ç·¨ç¢¼å¾Œçš„ç‰¹å¾µ
        """
        return self.encode(inputs)
    
    def get_frequency_bands(self) -> torch.Tensor:
        """ç²å–é »ç‡å¸¶"""
        return self.freq_bands
    
    def get_encoding_info(self) -> dict:
        """ç²å–ç·¨ç¢¼å™¨ä¿¡æ¯"""
        return {
            'input_dims': self.input_dims,
            'output_dims': self.out_dim,
            'num_freqs': self.num_freqs,
            'max_freq': 2**self.max_freq_log2,
            'include_input': self.include_input,
            'log_sampling': self.log_sampling
        }
    
    # é‡å­ç·¨ç¢¼æ¥å£ (æœªä¾†å¯¦ç¾)
    def quantum_encode(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        é‡å­ä½ç½®ç·¨ç¢¼ (ä½”ä½ç¬¦)
        
        æœªä¾†å¯ä»¥å¯¦ç¾ï¼š
        - é‡å­å‚…ç«‹è‘‰è®Šæ› (QFT)
        - è®Šåˆ†é‡å­é›»è·¯ç·¨ç¢¼
        - é‡å­ç‰¹å¾µæ˜ å°„
        
        Args:
            inputs: [..., input_dims] è¼¸å…¥åº§æ¨™
            
        Returns:
            encoded: [..., quantum_out_dim] é‡å­ç·¨ç¢¼ç‰¹å¾µ
        """
        if self.is_quantum_enabled():
            # TODO: å¯¦ç¾é‡å­ç·¨ç¢¼
            # å¯èƒ½çš„å¯¦ç¾ï¼š
            # 1. é‡å­å‚…ç«‹è‘‰è®Šæ›
            # 2. åƒæ•¸åŒ–é‡å­é›»è·¯
            # 3. é‡å­æ ¸æ–¹æ³•
            pass
        
        # å›é€€åˆ°ç¶“å…¸ç·¨ç¢¼
        return self.encode(inputs)


class MultiScalePositionalEncoder(PositionalEncoder):
    """
    å¤šå°ºåº¦ä½ç½®ç·¨ç¢¼å™¨
    
    åœ¨ä¸åŒå°ºåº¦ä¸Šæ‡‰ç”¨ä½ç½®ç·¨ç¢¼ï¼Œé©ç”¨æ–¼å¤šè§£æåº¦è¨“ç·´
    """
    
    def __init__(self, input_dims: int = 3, scales: List[int] = [1, 2, 4, 8],
                 num_freqs_per_scale: int = 4, include_input: bool = True):
        """
        åˆå§‹åŒ–å¤šå°ºåº¦ç·¨ç¢¼å™¨
        
        Args:
            input_dims: è¼¸å…¥ç¶­åº¦
            scales: ä¸åŒçš„å°ºåº¦åˆ—è¡¨
            num_freqs_per_scale: æ¯å€‹å°ºåº¦çš„é »ç‡æ•¸é‡
            include_input: æ˜¯å¦åŒ…å«åŸå§‹è¼¸å…¥
        """
        self.scales = scales
        self.num_freqs_per_scale = num_freqs_per_scale
        
        # è¨ˆç®—ç¸½é »ç‡æ•¸
        total_freqs = len(scales) * num_freqs_per_scale
        max_freq_log2 = int(np.log2(max(scales))) + num_freqs_per_scale - 1
        
        super().__init__(
            input_dims=input_dims,
            max_freq_log2=max_freq_log2,
            num_freqs=total_freqs,
            include_input=include_input
        )
        
        # é‡æ–°è¨ˆç®—é »ç‡å¸¶
        freq_bands = []
        for scale in scales:
            scale_freqs = 2.**torch.linspace(
                np.log2(scale), 
                np.log2(scale) + num_freqs_per_scale - 1, 
                steps=num_freqs_per_scale
            )
            freq_bands.append(scale_freqs)
        
        freq_bands = torch.cat(freq_bands)
        self.register_buffer('freq_bands', freq_bands)
        
        print(f"ğŸ”¢ å¤šå°ºåº¦ä½ç½®ç·¨ç¢¼å™¨:")
        print(f"   - å°ºåº¦: {scales}")
        print(f"   - æ¯å°ºåº¦é »ç‡æ•¸: {num_freqs_per_scale}")
        print(f"   - ç¸½é »ç‡æ•¸: {total_freqs}")


class AdaptivePositionalEncoder(PositionalEncoder):
    """
    è‡ªé©æ‡‰ä½ç½®ç·¨ç¢¼å™¨
    
    å¯ä»¥æ ¹æ“šè¨“ç·´é€²åº¦å‹•æ…‹èª¿æ•´ç·¨ç¢¼å¼·åº¦
    """
    
    def __init__(self, input_dims: int = 3, max_freq_log2: int = 10,
                 num_freqs: int = 10, include_input: bool = True,
                 warmup_steps: int = 1000):
        """
        åˆå§‹åŒ–è‡ªé©æ‡‰ç·¨ç¢¼å™¨
        
        Args:
            warmup_steps: é ç†±æ­¥æ•¸ï¼Œåœ¨æ­¤æœŸé–“é€æ¼¸å¢åŠ é »ç‡
        """
        super().__init__(input_dims, max_freq_log2, num_freqs, include_input)
        
        self.warmup_steps = warmup_steps
        self.current_step = 0
        
        print(f"ğŸ”¢ è‡ªé©æ‡‰ä½ç½®ç·¨ç¢¼å™¨:")
        print(f"   - é ç†±æ­¥æ•¸: {warmup_steps}")
    
    def encode(self, inputs: torch.Tensor, step: Optional[int] = None) -> torch.Tensor:
        """
        è‡ªé©æ‡‰ç·¨ç¢¼
        
        Args:
            inputs: [..., input_dims] è¼¸å…¥åº§æ¨™
            step: ç•¶å‰è¨“ç·´æ­¥æ•¸
            
        Returns:
            encoded: [..., out_dim] ç·¨ç¢¼å¾Œçš„ç‰¹å¾µ
        """
        if step is not None:
            self.current_step = step
        
        outputs = []
        
        # åŒ…å«åŸå§‹è¼¸å…¥
        if self.include_input:
            outputs.append(inputs)
        
        # è¨ˆç®—ç•¶å‰æ‡‰è©²ä½¿ç”¨çš„é »ç‡æ•¸é‡
        if self.current_step < self.warmup_steps:
            active_freqs = max(1, int(self.num_freqs * self.current_step / self.warmup_steps))
        else:
            active_freqs = self.num_freqs
        
        # å°æ´»èºçš„é »ç‡æ‡‰ç”¨ç·¨ç¢¼
        for i, freq in enumerate(self.freq_bands[:active_freqs]):
            for p_fn in self.periodic_fns:
                outputs.append(p_fn(inputs * freq))
        
        # å°æœªæ¿€æ´»çš„é »ç‡å¡«å……é›¶
        if active_freqs < self.num_freqs:
            remaining_dims = (self.num_freqs - active_freqs) * len(self.periodic_fns) * self.input_dims
            zeros = torch.zeros(*inputs.shape[:-1], remaining_dims, device=inputs.device)
            outputs.append(zeros)
        
        return torch.cat(outputs, dim=-1)


def create_positional_encoder(config: dict) -> PositionalEncoder:
    """
    æ ¹æ“šé…ç½®å‰µå»ºä½ç½®ç·¨ç¢¼å™¨
    
    Args:
        config: ç·¨ç¢¼å™¨é…ç½®
        
    Returns:
        encoder: ä½ç½®ç·¨ç¢¼å™¨å¯¦ä¾‹
    """
    encoder_type = config.get('type', 'standard')
    
    if encoder_type == 'standard':
        return PositionalEncoder(
            input_dims=config.get('input_dims', 3),
            max_freq_log2=config.get('max_freq_log2', 10),
            num_freqs=config.get('num_freqs', 10),
            include_input=config.get('include_input', True)
        )
    elif encoder_type == 'multiscale':
        return MultiScalePositionalEncoder(
            input_dims=config.get('input_dims', 3),
            scales=config.get('scales', [1, 2, 4, 8]),
            num_freqs_per_scale=config.get('num_freqs_per_scale', 4),
            include_input=config.get('include_input', True)
        )
    elif encoder_type == 'adaptive':
        return AdaptivePositionalEncoder(
            input_dims=config.get('input_dims', 3),
            max_freq_log2=config.get('max_freq_log2', 10),
            num_freqs=config.get('num_freqs', 10),
            include_input=config.get('include_input', True),
            warmup_steps=config.get('warmup_steps', 1000)
        )
    else:
        raise ValueError(f"æœªçŸ¥çš„ç·¨ç¢¼å™¨é¡å‹: {encoder_type}")


# è¼”åŠ©å‡½æ•¸
def visualize_encoding(encoder: PositionalEncoder, inputs: torch.Tensor, 
                      save_path: Optional[str] = None):
    """
    å¯è¦–åŒ–ä½ç½®ç·¨ç¢¼æ•ˆæœ
    
    Args:
        encoder: ä½ç½®ç·¨ç¢¼å™¨
        inputs: è¼¸å…¥åº§æ¨™
        save_path: ä¿å­˜è·¯å¾‘ (å¯é¸)
    """
    import matplotlib.pyplot as plt
    
    encoded = encoder.encode(inputs)
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # åŸå§‹åº§æ¨™
    for i, coord_name in enumerate(['X', 'Y', 'Z'][:inputs.shape[-1]]):
        if i < 2:
            axes[0, i].plot(inputs[:, i].numpy())
            axes[0, i].set_title(f'åŸå§‹ {coord_name} åº§æ¨™')
            axes[0, i].set_ylabel(f'{coord_name} å€¼')
    
    # ç·¨ç¢¼ç‰¹å¾µ
    axes[1, 0].imshow(encoded.T.numpy(), aspect='auto', cmap='viridis')
    axes[1, 0].set_title('ç·¨ç¢¼ç‰¹å¾µçŸ©é™£')
    axes[1, 0].set_xlabel('æ¨£æœ¬ç´¢å¼•')
    axes[1, 0].set_ylabel('ç‰¹å¾µç¶­åº¦')
    
    # é »ç‡éŸ¿æ‡‰
    freq_bands = encoder.get_frequency_bands()
    axes[1, 1].plot(freq_bands.numpy(), 'o-')
    axes[1, 1].set_title('é »ç‡å¸¶')
    axes[1, 1].set_xlabel('é »ç‡ç´¢å¼•')
    axes[1, 1].set_ylabel('é »ç‡å€¼')
    axes[1, 1].set_yscale('log')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    
    plt.show()


def test_encoding_properties(encoder: PositionalEncoder):
    """
    æ¸¬è©¦ç·¨ç¢¼å™¨çš„æ€§è³ª
    
    Args:
        encoder: ä½ç½®ç·¨ç¢¼å™¨
    """
    print(f"ğŸ§ª æ¸¬è©¦ä½ç½®ç·¨ç¢¼å™¨æ€§è³ª:")
    
    # æ¸¬è©¦è¼¸å…¥
    test_inputs = torch.tensor([
        [0.0, 0.0, 0.0],
        [1.0, 1.0, 1.0],
        [0.5, 0.5, 0.5],
        [-1.0, -1.0, -1.0]
    ])
    
    encoded = encoder.encode(test_inputs)
    
    print(f"   - è¼¸å…¥å½¢ç‹€: {test_inputs.shape}")
    print(f"   - è¼¸å‡ºå½¢ç‹€: {encoded.shape}")
    print(f"   - è¼¸å‡ºç¯„åœ: [{encoded.min():.3f}, {encoded.max():.3f}]")
    
    # æ¸¬è©¦ç¢ºå®šæ€§
    encoded2 = encoder.encode(test_inputs)
    is_deterministic = torch.allclose(encoded, encoded2)
    print(f"   - ç¢ºå®šæ€§: {'âœ…' if is_deterministic else 'âŒ'}")
    
    # æ¸¬è©¦ä¸åŒè¼¸å…¥ç”¢ç”Ÿä¸åŒè¼¸å‡º
    different_inputs = test_inputs + 0.1
    encoded_diff = encoder.encode(different_inputs)
    is_different = not torch.allclose(encoded, encoded_diff)
    print(f"   - å€åˆ†æ€§: {'âœ…' if is_different else 'âŒ'}")
    
    return {
        'deterministic': is_deterministic,
        'different_outputs': is_different,
        'output_range': (encoded.min().item(), encoded.max().item())
    } 