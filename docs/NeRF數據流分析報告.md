# NeRF æ•¸æ“šæµåˆ†æå ±å‘Š ğŸ“Š

## å ±å‘Šæ¦‚è¿°

æœ¬å ±å‘Šè©³ç´°åˆ†æäº† Neural Radiance Fields (NeRF) å¾åŸå§‹è¼¸å…¥æ•¸æ“šåˆ°æœ€çµ‚æ¸²æŸ“è¼¸å‡ºçš„å®Œæ•´æ•¸æ“šæµç¨‹ã€‚æˆ‘å€‘å°‡ä»¥ 100 å¼µä¸åŒè¦–è§’çš„åœ–åƒä½œç‚ºè¼¸å…¥ç¯„ä¾‹ï¼Œèªªæ˜æ•¸æ“šåœ¨æ•´å€‹ç³»çµ±ä¸­çš„æµå‹•ã€è™•ç†å’Œè½‰æ›éç¨‹ã€‚

## ğŸ“¸ è¼¸å…¥æ•¸æ“šçµæ§‹

### 1. åŸå§‹è¼¸å…¥æ•¸æ“š
```
è¼¸å…¥æ•¸æ“šé›†/
â”œâ”€â”€ ğŸ“ images/                  # åœ–åƒæ–‡ä»¶å¤¾
â”‚   â”œâ”€â”€ ğŸ“· img_001.jpg         # è¦–è§’ 1 çš„åœ–åƒ (800x600)
â”‚   â”œâ”€â”€ ğŸ“· img_002.jpg         # è¦–è§’ 2 çš„åœ–åƒ (800x600)
â”‚   â”œâ”€â”€ ...                    # ...
â”‚   â””â”€â”€ ğŸ“· img_100.jpg         # è¦–è§’ 100 çš„åœ–åƒ (800x600)
â”œâ”€â”€ ğŸ“„ camera_poses.json       # ç›¸æ©Ÿä½ç½®å’Œæ–¹å‘
â”œâ”€â”€ ğŸ“„ camera_intrinsics.json  # ç›¸æ©Ÿå…§åƒ
â””â”€â”€ ğŸ“„ scene_metadata.json     # å ´æ™¯å…ƒæ•¸æ“š
```

### 2. æ•¸æ“šè©³ç´°èªªæ˜

#### åœ–åƒæ•¸æ“š (Images)
- **æ•¸é‡**: 100 å¼µåœ–åƒ
- **è§£æåº¦**: 800Ã—600 åƒç´  (å¯èª¿æ•´)
- **æ ¼å¼**: RGB å½©è‰²åœ–åƒ
- **å…§å®¹**: åŒä¸€å€‹ 3D å ´æ™¯çš„ä¸åŒè¦–è§’
- **å‘½å**: æŒ‰é †åºç·¨è™Ÿ (img_001.jpg åˆ° img_100.jpg)

#### ç›¸æ©Ÿåƒæ•¸ (Camera Parameters)
```json
{
  "img_001.jpg": {
    "pose": [
      [0.9999, 0.0000, 0.0000, 2.5],    # æ—‹è½‰çŸ©é™£ + å¹³ç§»å‘é‡
      [0.0000, 0.8660, -0.5000, 1.5],   # 4x4 è®Šæ›çŸ©é™£
      [0.0000, 0.5000, 0.8660, 3.0],
      [0.0000, 0.0000, 0.0000, 1.0]
    ],
    "intrinsics": {
      "focal_length": 525.0,             # ç„¦è·
      "cx": 400.0,                       # ä¸»é» x åº§æ¨™
      "cy": 300.0                        # ä¸»é» y åº§æ¨™
    }
  }
}
```

## ğŸ”„ æ•¸æ“šæµç¨‹è©³ç´°åˆ†æ

### éšæ®µ 1: æ•¸æ“šé è™•ç† (Data Preprocessing)

#### 1.1 åœ–åƒè¼‰å…¥èˆ‡æ¨™æº–åŒ–
```python
# è¼¸å…¥: åŸå§‹åœ–åƒæ–‡ä»¶
raw_images = load_images("images/")  # Shape: (100, 800, 600, 3)

# è™•ç†: æ¨™æº–åŒ–åˆ° [0, 1] ç¯„åœ
normalized_images = raw_images / 255.0

# è¼¸å‡º: æ¨™æº–åŒ–åœ–åƒå¼µé‡
# Shape: (100, 800, 600, 3), dtype: float32
```

#### 1.2 ç›¸æ©Ÿåƒæ•¸è§£æ
```python
# è¼¸å…¥: ç›¸æ©Ÿåƒæ•¸ JSON æ–‡ä»¶
camera_data = load_camera_parameters()

# è™•ç†: æå–ä½å§¿çŸ©é™£å’Œå…§åƒ
poses = extract_poses(camera_data)      # Shape: (100, 4, 4)
intrinsics = extract_intrinsics(camera_data)  # Shape: (100, 3, 3)

# è¼¸å‡º: ç›¸æ©Ÿä½å§¿å’Œå…§åƒçŸ©é™£
```

#### 1.3 æ•¸æ“šåˆ†å‰²
```python
# è¼¸å…¥: 100 å¼µåœ–åƒå’Œå°æ‡‰çš„ç›¸æ©Ÿåƒæ•¸
total_images = 100

# è™•ç†: æŒ‰æ¯”ä¾‹åˆ†å‰²æ•¸æ“š
train_indices = range(0, 80)      # 80 å¼µè¨“ç·´åœ–åƒ
val_indices = range(80, 90)       # 10 å¼µé©—è­‰åœ–åƒ  
test_indices = range(90, 100)     # 10 å¼µæ¸¬è©¦åœ–åƒ

# è¼¸å‡º: åˆ†å‰²å¾Œçš„æ•¸æ“šé›†
train_data = {
    'images': images[train_indices],    # Shape: (80, 800, 600, 3)
    'poses': poses[train_indices],      # Shape: (80, 4, 4)
    'intrinsics': intrinsics[train_indices]  # Shape: (80, 3, 3)
}
```

### éšæ®µ 2: å°„ç·šç”Ÿæˆ (Ray Generation)

#### 2.1 åƒç´ åº§æ¨™ç”Ÿæˆ
```python
# è¼¸å…¥: åœ–åƒå°ºå¯¸
height, width = 600, 800

# è™•ç†: ç”Ÿæˆåƒç´ ç¶²æ ¼
i, j = torch.meshgrid(
    torch.linspace(0, width-1, width),   # x åº§æ¨™
    torch.linspace(0, height-1, height)  # y åº§æ¨™
)

# è¼¸å‡º: åƒç´ åº§æ¨™ç¶²æ ¼
# i.shape: (600, 800), j.shape: (600, 800)
```

#### 2.2 å°„ç·šæ–¹å‘è¨ˆç®—
```python
# è¼¸å…¥: åƒç´ åº§æ¨™å’Œç›¸æ©Ÿå…§åƒ
focal_length = 525.0
cx, cy = 400.0, 300.0

# è™•ç†: è½‰æ›ç‚ºç›¸æ©Ÿåº§æ¨™ç³»
dirs = torch.stack([
    (i - cx) / focal_length,      # x æ–¹å‘
    -(j - cy) / focal_length,     # y æ–¹å‘ (æ³¨æ„è² è™Ÿ)
    -torch.ones_like(i)           # z æ–¹å‘ (æœå‘å ´æ™¯)
], dim=-1)

# è¼¸å‡º: å°„ç·šæ–¹å‘å‘é‡
# dirs.shape: (600, 800, 3)
```

#### 2.3 ä¸–ç•Œåº§æ¨™ç³»è½‰æ›
```python
# è¼¸å…¥: ç›¸æ©Ÿåº§æ¨™ç³»å°„ç·šæ–¹å‘å’Œç›¸æ©Ÿä½å§¿
camera_pose = poses[0]  # ç¬¬ä¸€å¼µåœ–åƒçš„ä½å§¿

# è™•ç†: æ—‹è½‰åˆ°ä¸–ç•Œåº§æ¨™ç³»
rays_d = torch.sum(dirs[..., None, :] * camera_pose[:3, :3], dim=-1)

# è™•ç†: å°„ç·šèµ·é» (ç›¸æ©Ÿä½ç½®)
rays_o = camera_pose[:3, -1].expand(rays_d.shape)

# è¼¸å‡º: ä¸–ç•Œåº§æ¨™ç³»ä¸­çš„å°„ç·š
# rays_o.shape: (600, 800, 3) - å°„ç·šèµ·é»
# rays_d.shape: (600, 800, 3) - å°„ç·šæ–¹å‘
```

### éšæ®µ 3: è¨“ç·´æ•¸æ“šæ¡æ¨£ (Training Data Sampling)

#### 3.1 éš¨æ©Ÿå°„ç·šæ¡æ¨£
```python
# è¼¸å…¥: ä¸€å¼µè¨“ç·´åœ–åƒçš„æ‰€æœ‰å°„ç·š
total_rays = height * width  # 600 * 800 = 480,000 æ¢å°„ç·š
batch_size = 1024

# è™•ç†: éš¨æ©Ÿé¸æ“‡å°„ç·š
ray_indices = torch.randperm(total_rays)[:batch_size]

# è¼¸å‡º: æ‰¹æ¬¡å°„ç·šæ•¸æ“š
batch_rays_o = rays_o.reshape(-1, 3)[ray_indices]  # Shape: (1024, 3)
batch_rays_d = rays_d.reshape(-1, 3)[ray_indices]  # Shape: (1024, 3)
batch_target_rgb = target_image.reshape(-1, 3)[ray_indices]  # Shape: (1024, 3)
```

### éšæ®µ 4: 3D é»æ¡æ¨£ (3D Point Sampling)

#### 4.1 æ²¿å°„ç·šæ¡æ¨£é»
```python
# è¼¸å…¥: å°„ç·šåƒæ•¸
near, far = 2.0, 6.0  # è¿‘å¹³é¢å’Œé å¹³é¢
n_samples = 64        # æ¯æ¢å°„ç·šæ¡æ¨£ 64 å€‹é»

# è™•ç†: åˆ†å±¤æ¡æ¨£
t_vals = torch.linspace(0., 1., steps=n_samples)
z_vals = near * (1. - t_vals) + far * t_vals  # æ·±åº¦å€¼

# è™•ç†: æ·»åŠ éš¨æ©Ÿæ“¾å‹• (è¨“ç·´æ™‚)
if training:
    mids = 0.5 * (z_vals[..., 1:] + z_vals[..., :-1])
    upper = torch.cat([mids, z_vals[..., -1:]], -1)
    lower = torch.cat([z_vals[..., :1], mids], -1)
    t_rand = torch.rand(z_vals.shape)
    z_vals = lower + (upper - lower) * t_rand

# è¼¸å‡º: æ¡æ¨£æ·±åº¦
# z_vals.shape: (1024, 64)
```

#### 4.2 è¨ˆç®— 3D é»åº§æ¨™
```python
# è¼¸å…¥: å°„ç·šèµ·é»ã€æ–¹å‘å’Œæ·±åº¦å€¼
# è™•ç†: è¨ˆç®— 3D é»ä½ç½®
pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., :, None]

# è¼¸å‡º: 3D é»åº§æ¨™
# pts.shape: (1024, 64, 3)
```

### éšæ®µ 5: ä½ç½®ç·¨ç¢¼ (Positional Encoding)

#### 5.1 æ­£å¼¦é¤˜å¼¦ç·¨ç¢¼
```python
# è¼¸å…¥: 3D é»åº§æ¨™
input_pts = pts.reshape(-1, 3)  # Shape: (65536, 3)

# è™•ç†: å¤šé »ç‡ç·¨ç¢¼
L = 10  # é »ç‡æ•¸é‡
encoded_pts = [input_pts]  # åŒ…å«åŸå§‹åº§æ¨™

for i in range(L):
    freq = 2.**i
    encoded_pts.append(torch.sin(freq * input_pts))
    encoded_pts.append(torch.cos(freq * input_pts))

# è¼¸å‡º: ç·¨ç¢¼å¾Œçš„ä½ç½®ç‰¹å¾µ
encoded_pts = torch.cat(encoded_pts, dim=-1)
# encoded_pts.shape: (65536, 63)  # 3 + 3*2*10 = 63
```

#### 5.2 è§€çœ‹æ–¹å‘ç·¨ç¢¼
```python
# è¼¸å…¥: å°„ç·šæ–¹å‘
viewdirs = rays_d / torch.norm(rays_d, dim=-1, keepdim=True)
viewdirs = viewdirs[:, None].expand(pts.shape)  # æ“´å±•åˆ°æ‰€æœ‰æ¡æ¨£é»

# è™•ç†: æ–¹å‘ç·¨ç¢¼ (è¼ƒå°‘é »ç‡)
L_dir = 4
encoded_dirs = [viewdirs.reshape(-1, 3)]

for i in range(L_dir):
    freq = 2.**i
    encoded_dirs.append(torch.sin(freq * viewdirs.reshape(-1, 3)))
    encoded_dirs.append(torch.cos(freq * viewdirs.reshape(-1, 3)))

# è¼¸å‡º: ç·¨ç¢¼å¾Œçš„æ–¹å‘ç‰¹å¾µ
encoded_dirs = torch.cat(encoded_dirs, dim=-1)
# encoded_dirs.shape: (65536, 27)  # 3 + 3*2*4 = 27
```

### éšæ®µ 6: NeRF ç¶²çµ¡æ¨ç† (NeRF Network Inference)

#### 6.1 ç¶²çµ¡å‰å‘å‚³æ’­
```python
# è¼¸å…¥: ç·¨ç¢¼å¾Œçš„ä½ç½®å’Œæ–¹å‘ç‰¹å¾µ
# encoded_pts.shape: (65536, 63)
# encoded_dirs.shape: (65536, 27)

# è™•ç†: é€šé NeRF ç¶²çµ¡
rgb, density = nerf_network(encoded_pts, encoded_dirs)

# è¼¸å‡º: é¡è‰²å’Œå¯†åº¦é æ¸¬
# rgb.shape: (65536, 3)      # RGB é¡è‰²å€¼ [0, 1]
# density.shape: (65536, 1)  # é«”ç©å¯†åº¦å€¼ [0, +âˆ]
```

#### 6.2 é‡å¡‘ç‚ºå°„ç·šæ ¼å¼
```python
# è¼¸å…¥: å¹³å¦åŒ–çš„é æ¸¬çµæœ
# è™•ç†: é‡å¡‘å›å°„ç·šÃ—æ¡æ¨£é»æ ¼å¼
rgb = rgb.reshape(1024, 64, 3)      # (batch_rays, n_samples, 3)
density = density.reshape(1024, 64, 1)  # (batch_rays, n_samples, 1)

# è¼¸å‡º: æŒ‰å°„ç·šçµ„ç¹”çš„é æ¸¬çµæœ
```

### éšæ®µ 7: é«”ç©æ¸²æŸ“ (Volume Rendering)

#### 7.1 è¨ˆç®—é€å°„ç‡å’Œæ¬Šé‡
```python
# è¼¸å…¥: å¯†åº¦å€¼å’Œæ·±åº¦é–“éš”
# è™•ç†: è¨ˆç®—ç›¸é„°é»é–“è·é›¢
dists = z_vals[..., 1:] - z_vals[..., :-1]
dists = torch.cat([dists, torch.tensor([1e10]).expand(dists[..., :1].shape)], -1)

# è™•ç†: è¨ˆç®— alpha å€¼ (å°„ç·šçµ‚æ­¢æ©Ÿç‡)
alpha = 1. - torch.exp(-density[..., 0] * dists)

# è™•ç†: è¨ˆç®—é€å°„ç‡ (å…‰ç·šåˆ°é”è©²é»çš„æ©Ÿç‡)
transmittance = torch.cumprod(
    torch.cat([torch.ones((alpha.shape[0], 1)), 1. - alpha + 1e-10], -1), -1
)[:, :-1]

# è™•ç†: è¨ˆç®—é‡è¦æ€§æ¬Šé‡
weights = alpha * transmittance

# è¼¸å‡º: æ¬Šé‡çŸ©é™£
# weights.shape: (1024, 64)
```

#### 7.2 é¡è‰²ç©åˆ†
```python
# è¼¸å…¥: RGB å€¼å’Œæ¬Šé‡
# è™•ç†: åŠ æ¬Šå¹³å‡å¾—åˆ°æœ€çµ‚åƒç´ é¡è‰²
rgb_map = torch.sum(weights[..., None] * rgb, dim=-2)

# è™•ç†: è¨ˆç®—æ·±åº¦åœ–
depth_map = torch.sum(weights * z_vals, dim=-1)

# è¼¸å‡º: æ¸²æŸ“çµæœ
# rgb_map.shape: (1024, 3)  # æœ€çµ‚åƒç´ é¡è‰²
# depth_map.shape: (1024,)  # æ·±åº¦å€¼
```

### éšæ®µ 8: æå¤±è¨ˆç®—èˆ‡åå‘å‚³æ’­ (Loss Computation & Backpropagation)

#### 8.1 æå¤±è¨ˆç®—
```python
# è¼¸å…¥: é æ¸¬é¡è‰²å’ŒçœŸå¯¦é¡è‰²
predicted_rgb = rgb_map      # Shape: (1024, 3)
target_rgb = batch_target_rgb  # Shape: (1024, 3)

# è™•ç†: è¨ˆç®— MSE æå¤±
mse_loss = torch.mean((predicted_rgb - target_rgb) ** 2)

# è™•ç†: è¨ˆç®— PSNR æŒ‡æ¨™
psnr = -10. * torch.log10(mse_loss)

# è¼¸å‡º: æå¤±å€¼å’ŒæŒ‡æ¨™
# mse_loss: æ¨™é‡
# psnr: æ¨™é‡ (dB)
```

#### 8.2 æ¢¯åº¦æ›´æ–°
```python
# è¼¸å…¥: æå¤±å€¼
# è™•ç†: åå‘å‚³æ’­
optimizer.zero_grad()
mse_loss.backward()
optimizer.step()

# è¼¸å‡º: æ›´æ–°å¾Œçš„ç¶²çµ¡åƒæ•¸
```

## ğŸ“Š æ•¸æ“šé›†åˆ†å‰²ç­–ç•¥

### è¨“ç·´é›† (Training Set) - 80 å¼µåœ–åƒ
- **ç”¨é€”**: è¨“ç·´ NeRF ç¶²çµ¡åƒæ•¸
- **ç‰¹é»**: 
  - éš¨æ©Ÿå°„ç·šæ¡æ¨£
  - æ¯å€‹ epoch ä½¿ç”¨ä¸åŒçš„å°„ç·šçµ„åˆ
  - åŒ…å«æ•¸æ“šå¢å¼· (å°„ç·šæ“¾å‹•)

### é©—è­‰é›† (Validation Set) - 10 å¼µåœ–åƒ  
- **ç”¨é€”**: ç›£æ§è¨“ç·´éç¨‹ï¼Œé˜²æ­¢éæ“¬åˆ
- **ç‰¹é»**:
  - å›ºå®šçš„è©•ä¼°æµç¨‹
  - ä¸åƒèˆ‡æ¢¯åº¦æ›´æ–°
  - ç”¨æ–¼æ—©åœå’Œè¶…åƒæ•¸èª¿æ•´

### æ¸¬è©¦é›† (Test Set) - 10 å¼µåœ–åƒ
- **ç”¨é€”**: æœ€çµ‚æ€§èƒ½è©•ä¼°
- **ç‰¹é»**:
  - å®Œå…¨æœªè¦‹éçš„è¦–è§’
  - ç”¨æ–¼å ±å‘Šæœ€çµ‚çµæœ
  - è©•ä¼°æ³›åŒ–èƒ½åŠ›

## ğŸ”„ å®Œæ•´æ•¸æ“šæµç¨‹åœ–

```
åŸå§‹æ•¸æ“š (100 å¼µåœ–åƒ)
         â†“
    æ•¸æ“šé è™•ç†
    â”œâ”€â”€ åœ–åƒæ¨™æº–åŒ–
    â”œâ”€â”€ ç›¸æ©Ÿåƒæ•¸è§£æ  
    â””â”€â”€ æ•¸æ“šé›†åˆ†å‰²
         â†“
    å°„ç·šç”Ÿæˆ (æ¯å¼µåœ–åƒ 480,000 æ¢å°„ç·š)
    â”œâ”€â”€ åƒç´ åº§æ¨™ â†’ ç›¸æ©Ÿåº§æ¨™
    â”œâ”€â”€ ç›¸æ©Ÿåº§æ¨™ â†’ ä¸–ç•Œåº§æ¨™
    â””â”€â”€ å°„ç·šèµ·é» + æ–¹å‘
         â†“
    è¨“ç·´æ¡æ¨£ (æ¯æ‰¹æ¬¡ 1,024 æ¢å°„ç·š)
         â†“
    3D é»æ¡æ¨£ (æ¯æ¢å°„ç·š 64 å€‹é»)
         â†“
    ä½ç½®ç·¨ç¢¼
    â”œâ”€â”€ 3D åº§æ¨™ â†’ 63 ç¶­ç‰¹å¾µ
    â””â”€â”€ è§€çœ‹æ–¹å‘ â†’ 27 ç¶­ç‰¹å¾µ
         â†“
    NeRF ç¶²çµ¡æ¨ç†
    â”œâ”€â”€ è¼¸å…¥: (65,536, 63+27)
    â””â”€â”€ è¼¸å‡º: RGB (65,536, 3) + å¯†åº¦ (65,536, 1)
         â†“
    é«”ç©æ¸²æŸ“
    â”œâ”€â”€ é€å°„ç‡è¨ˆç®—
    â”œâ”€â”€ æ¬Šé‡è¨ˆç®—
    â””â”€â”€ é¡è‰²ç©åˆ†
         â†“
    æå¤±è¨ˆç®— & åå‘å‚³æ’­
    â”œâ”€â”€ MSE æå¤±
    â”œâ”€â”€ PSNR æŒ‡æ¨™
    â””â”€â”€ æ¢¯åº¦æ›´æ–°
         â†“
    æ¸²æŸ“è¼¸å‡º (æ–°è¦–è§’åœ–åƒ)
```

## ğŸ“ˆ æ•¸æ“šé‡ç´šåˆ†æ

### è¨˜æ†¶é«”ä½¿ç”¨ä¼°ç®—
```
å–®å¼µåœ–åƒæ•¸æ“š:
- åŸå§‹åœ–åƒ: 800Ã—600Ã—3Ã—4 bytes = 7.2 MB
- å°„ç·šæ•¸æ“š: 480,000Ã—6Ã—4 bytes = 11.5 MB (èµ·é»+æ–¹å‘)
- æ¡æ¨£é»: 480,000Ã—64Ã—3Ã—4 bytes = 368 MB

æ‰¹æ¬¡è¨“ç·´æ•¸æ“š:
- å°„ç·šæ‰¹æ¬¡: 1,024Ã—6Ã—4 bytes = 24.6 KB
- æ¡æ¨£é»: 1,024Ã—64Ã—3Ã—4 bytes = 786 KB  
- ç·¨ç¢¼ç‰¹å¾µ: 65,536Ã—90Ã—4 bytes = 23.6 MB
- ç¶²çµ¡è¼¸å‡º: 65,536Ã—4Ã—4 bytes = 1.0 MB
```

### è¨ˆç®—è¤‡é›œåº¦
```
æ¯å€‹è¨“ç·´æ­¥é©Ÿ:
- å°„ç·šæ¡æ¨£: O(1) - éš¨æ©Ÿç´¢å¼•
- 3D é»æ¡æ¨£: O(batch_size Ã— n_samples)
- ä½ç½®ç·¨ç¢¼: O(batch_size Ã— n_samples Ã— encoding_dim)
- ç¶²çµ¡æ¨ç†: O(batch_size Ã— n_samples Ã— network_params)
- é«”ç©æ¸²æŸ“: O(batch_size Ã— n_samples)

ç¸½è¤‡é›œåº¦: O(batch_size Ã— n_samples Ã— max(encoding_dim, network_params))
```

## ğŸ¯ é—œéµæ•¸æ“šæµç‰¹é»

### 1. å¤šå°ºåº¦è™•ç†
- **åœ–åƒç´š**: æ•´å¼µåœ–åƒçš„ç›¸æ©Ÿåƒæ•¸
- **å°„ç·šç´š**: æ¯å€‹åƒç´ å°æ‡‰ä¸€æ¢å°„ç·š  
- **é»ç´š**: æ¯æ¢å°„ç·šä¸Šçš„å¤šå€‹æ¡æ¨£é»

### 2. éš¨æ©Ÿæ€§å¼•å…¥
- **å°„ç·šæ¡æ¨£**: æ¯æ‰¹æ¬¡éš¨æ©Ÿé¸æ“‡å°„ç·š
- **é»æ¡æ¨£**: åˆ†å±¤æ¡æ¨£ä¸­çš„éš¨æ©Ÿæ“¾å‹•
- **æ•¸æ“šå¢å¼·**: å¯é¸çš„å°„ç·šæŠ–å‹•

### 3. ç¶­åº¦è®Šæ›
- **2D â†’ 3D**: åƒç´ åº§æ¨™ â†’ ä¸–ç•Œåº§æ¨™
- **3D â†’ é«˜ç¶­**: ä½ç½®ç·¨ç¢¼æ“´å±•ç‰¹å¾µç¶­åº¦
- **é«˜ç¶­ â†’ 3D**: ç¶²çµ¡è¼¸å‡º RGB + å¯†åº¦
- **3D â†’ 2D**: é«”ç©æ¸²æŸ“å›åˆ°åƒç´ é¡è‰²

### 4. ä¸¦è¡Œè™•ç†
- **æ‰¹æ¬¡ä¸¦è¡Œ**: åŒæ™‚è™•ç†å¤šæ¢å°„ç·š
- **é»ä¸¦è¡Œ**: åŒæ™‚è™•ç†å°„ç·šä¸Šçš„å¤šå€‹é»
- **GPU åŠ é€Ÿ**: æ‰€æœ‰è¨ˆç®—éƒ½å¯ä»¥å‘é‡åŒ–

## ğŸ“ ç¸½çµ

NeRF çš„æ•¸æ“šæµç¨‹æ˜¯ä¸€å€‹è¤‡é›œä½†å„ªé›…çš„ç®¡é“ï¼Œå®ƒå°‡ 2D åœ–åƒè§€æ¸¬è½‰æ›ç‚º 3D å ´æ™¯çš„éš±å¼è¡¨ç¤ºã€‚é—œéµåœ¨æ–¼ï¼š

1. **æ•¸æ“šçµ„ç¹”**: å¾åœ–åƒåˆ°å°„ç·šåˆ°é»çš„å±¤æ¬¡åŒ–çµæ§‹
2. **ç‰¹å¾µç·¨ç¢¼**: ä½ç½®ç·¨ç¢¼æä¾›é«˜é »ç´°ç¯€è¡¨ç¤ºèƒ½åŠ›  
3. **é«”ç©æ¸²æŸ“**: ç‰©ç†ä¸Šåˆç†çš„ 3D åˆ° 2D æŠ•å½±éç¨‹
4. **ç«¯åˆ°ç«¯è¨“ç·´**: ç›´æ¥å¾ 2D ç›£ç£ä¿¡è™Ÿå­¸ç¿’ 3D è¡¨ç¤º

é€™å€‹æ•¸æ“šæµè¨­è¨ˆä½¿å¾— NeRF èƒ½å¤ å¾æœ‰é™çš„ 2D è§€æ¸¬ä¸­å­¸ç¿’åˆ°è±å¯Œçš„ 3D å ´æ™¯è¡¨ç¤ºï¼Œä¸¦èƒ½å¤ æ¸²æŸ“å‡ºé«˜è³ªé‡çš„æ–°è¦–è§’åœ–åƒã€‚ 